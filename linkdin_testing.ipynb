{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = \"AQU9ocuSvBRaOMAPcXmQTJBP-ntg0qIecfEmbL_ZIMSkibAK-ZuuHCxhajCH3AGtYIbC8gteyB8Ti8unuLlYo0hCpIWHb015-R5BgSH2b9XvP2cqaPg0FSBg7TKsqyqKy-Cm_6lqeWuennYXqbd5AZEa2NhS7zXfkV3p7QHLRAsDmbuDs7FkfKBKZi9t0q8GdoXrocHfjerlqqP1prqDxSIsWFbd2UBsOjDyEa8azISP7Cu2wywpvZCF69TOBUgbF_rDf2jETrZAREtJlv26gjn7hSde6octuWSTiZXdBnTu79ACPgI2use1kc7zzT7PMF2qftWziCIncyRgGD620fEOaovrUQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "class LinkedInShare:\n",
    "    \"\"\"\n",
    "    A Python wrapper for the LinkedIn Share API.\n",
    "    This class provides methods to post content to LinkedIn, including text, articles/URLs, and images/videos.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, access_token):\n",
    "        \"\"\"\n",
    "        Initialize the LinkedIn API wrapper with an OAuth 2.0 access token.\n",
    "        \n",
    "        Args:\n",
    "            access_token (str): OAuth 2.0 access token with w_member_social scope\n",
    "        \"\"\"\n",
    "        self.access_token = access_token\n",
    "        self.base_url = \"https://api.linkedin.com/v2\"\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {access_token}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"X-Restli-Protocol-Version\": \"2.0.0\"\n",
    "        }\n",
    "        \n",
    "        # Get person URN (if not provided)\n",
    "        self.person_urn = None\n",
    "    \n",
    "    def get_profile(self):\n",
    "        \"\"\"\n",
    "        Get the profile information of the authenticated user to retrieve the Person URN.\n",
    "        \n",
    "        Returns:\n",
    "            dict: Profile information\n",
    "        \"\"\"\n",
    "        url = f\"{self.base_url}/me\"\n",
    "        response = requests.get(url, headers=self.headers)\n",
    "        response.raise_for_status()\n",
    "        profile_data = response.json()\n",
    "        self.person_urn = f\"urn:li:person:{profile_data['id']}\"\n",
    "        return profile_data\n",
    "    \n",
    "    def post_text(self, text, visibility=\"PUBLIC\"):\n",
    "        \"\"\"\n",
    "        Create a simple text post on LinkedIn.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The text content of the post\n",
    "            visibility (str): Visibility of the post, either \"PUBLIC\" or \"CONNECTIONS\"\n",
    "            \n",
    "        Returns:\n",
    "            str: ID of the created post\n",
    "        \"\"\"\n",
    "        if not self.person_urn:\n",
    "            self.get_profile()\n",
    "            \n",
    "        url = f\"{self.base_url}/ugcPosts\"\n",
    "        \n",
    "        payload = {\n",
    "            \"author\": self.person_urn,\n",
    "            \"lifecycleState\": \"PUBLISHED\",\n",
    "            \"specificContent\": {\n",
    "                \"com.linkedin.ugc.ShareContent\": {\n",
    "                    \"shareCommentary\": {\n",
    "                        \"text\": text\n",
    "                    },\n",
    "                    \"shareMediaCategory\": \"NONE\"\n",
    "                }\n",
    "            },\n",
    "            \"visibility\": {\n",
    "                \"com.linkedin.ugc.MemberNetworkVisibility\": visibility\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, headers=self.headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.headers.get('X-RestLi-Id')\n",
    "    \n",
    "    def post_article(self, text, article_url, title=None, description=None, visibility=\"PUBLIC\"):\n",
    "        \"\"\"\n",
    "        Create a post with an article or URL on LinkedIn.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The text content of the post\n",
    "            article_url (str): URL to share\n",
    "            title (str, optional): Custom title for the article\n",
    "            description (str, optional): Custom description for the article\n",
    "            visibility (str): Visibility of the post, either \"PUBLIC\" or \"CONNECTIONS\"\n",
    "            \n",
    "        Returns:\n",
    "            str: ID of the created post\n",
    "        \"\"\"\n",
    "        if not self.person_urn:\n",
    "            self.get_profile()\n",
    "            \n",
    "        url = f\"{self.base_url}/ugcPosts\"\n",
    "        \n",
    "        media = {\n",
    "            \"status\": \"READY\",\n",
    "            \"originalUrl\": article_url\n",
    "        }\n",
    "        \n",
    "        if title:\n",
    "            media[\"title\"] = {\"text\": title}\n",
    "        \n",
    "        if description:\n",
    "            media[\"description\"] = {\"text\": description}\n",
    "        \n",
    "        payload = {\n",
    "            \"author\": self.person_urn,\n",
    "            \"lifecycleState\": \"PUBLISHED\",\n",
    "            \"specificContent\": {\n",
    "                \"com.linkedin.ugc.ShareContent\": {\n",
    "                    \"shareCommentary\": {\n",
    "                        \"text\": text\n",
    "                    },\n",
    "                    \"shareMediaCategory\": \"ARTICLE\",\n",
    "                    \"media\": [media]\n",
    "                }\n",
    "            },\n",
    "            \"visibility\": {\n",
    "                \"com.linkedin.ugc.MemberNetworkVisibility\": visibility\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, headers=self.headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.headers.get('X-RestLi-Id')\n",
    "    \n",
    "    def register_upload(self, media_type=\"image\"):\n",
    "        \"\"\"\n",
    "        Register an image or video upload with LinkedIn.\n",
    "        \n",
    "        Args:\n",
    "            media_type (str): Either \"image\" or \"video\"\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (upload_url, asset_id)\n",
    "        \"\"\"\n",
    "        if not self.person_urn:\n",
    "            self.get_profile()\n",
    "            \n",
    "        url = f\"{self.base_url}/assets?action=registerUpload\"\n",
    "        \n",
    "        recipe = \"urn:li:digitalmediaRecipe:feedshare-image\" if media_type == \"image\" else \"urn:li:digitalmediaRecipe:feedshare-video\"\n",
    "        \n",
    "        payload = {\n",
    "            \"registerUploadRequest\": {\n",
    "                \"recipes\": [recipe],\n",
    "                \"owner\": self.person_urn,\n",
    "                \"serviceRelationships\": [\n",
    "                    {\n",
    "                        \"relationshipType\": \"OWNER\",\n",
    "                        \"identifier\": \"urn:li:userGeneratedContent\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, headers=self.headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        upload_url = data[\"value\"][\"uploadMechanism\"][\"com.linkedin.digitalmedia.uploading.MediaUploadHttpRequest\"][\"uploadUrl\"]\n",
    "        asset_id = data[\"value\"][\"asset\"]\n",
    "        \n",
    "        return upload_url, asset_id\n",
    "    \n",
    "    def upload_media(self, upload_url, file_path):\n",
    "        \"\"\"\n",
    "        Upload an image or video file to LinkedIn.\n",
    "        \n",
    "        Args:\n",
    "            upload_url (str): URL obtained from register_upload\n",
    "            file_path (str): Path to the local image or video file\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if upload was successful\n",
    "        \"\"\"\n",
    "        with open(file_path, 'rb') as file:\n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {self.access_token}\"\n",
    "            }\n",
    "            response = requests.post(upload_url, headers=headers, data=file)\n",
    "            response.raise_for_status()\n",
    "            return True\n",
    "    \n",
    "    def post_image(self, text, image_path, title=None, description=None, visibility=\"PUBLIC\"):\n",
    "        \"\"\"\n",
    "        Create a post with an image on LinkedIn.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The text content of the post\n",
    "            image_path (str): Path to the local image file\n",
    "            title (str, optional): Custom title for the image\n",
    "            description (str, optional): Custom description for the image\n",
    "            visibility (str): Visibility of the post, either \"PUBLIC\" or \"CONNECTIONS\"\n",
    "            \n",
    "        Returns:\n",
    "            str: ID of the created post\n",
    "        \"\"\"\n",
    "        # Register upload\n",
    "        upload_url, asset_id = self.register_upload(media_type=\"image\")\n",
    "        \n",
    "        # Upload image\n",
    "        self.upload_media(upload_url, image_path)\n",
    "        \n",
    "        # Create post with the uploaded image\n",
    "        url = f\"{self.base_url}/ugcPosts\"\n",
    "        \n",
    "        media = {\n",
    "            \"status\": \"READY\",\n",
    "            \"media\": asset_id\n",
    "        }\n",
    "        \n",
    "        if title:\n",
    "            media[\"title\"] = {\"text\": title}\n",
    "        \n",
    "        if description:\n",
    "            media[\"description\"] = {\"text\": description}\n",
    "        \n",
    "        payload = {\n",
    "            \"author\": self.person_urn,\n",
    "            \"lifecycleState\": \"PUBLISHED\",\n",
    "            \"specificContent\": {\n",
    "                \"com.linkedin.ugc.ShareContent\": {\n",
    "                    \"shareCommentary\": {\n",
    "                        \"text\": text\n",
    "                    },\n",
    "                    \"shareMediaCategory\": \"IMAGE\",\n",
    "                    \"media\": [media]\n",
    "                }\n",
    "            },\n",
    "            \"visibility\": {\n",
    "                \"com.linkedin.ugc.MemberNetworkVisibility\": visibility\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, headers=self.headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.headers.get('X-RestLi-Id')\n",
    "    \n",
    "    def post_video(self, text, video_path, title=None, description=None, visibility=\"PUBLIC\"):\n",
    "        \"\"\"\n",
    "        Create a post with a video on LinkedIn.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The text content of the post\n",
    "            video_path (str): Path to the local video file\n",
    "            title (str, optional): Custom title for the video\n",
    "            description (str, optional): Custom description for the video\n",
    "            visibility (str): Visibility of the post, either \"PUBLIC\" or \"CONNECTIONS\"\n",
    "            \n",
    "        Returns:\n",
    "            str: ID of the created post\n",
    "        \"\"\"\n",
    "        # Register upload\n",
    "        upload_url, asset_id = self.register_upload(media_type=\"video\")\n",
    "        \n",
    "        # Upload video\n",
    "        self.upload_media(upload_url, video_path)\n",
    "        \n",
    "        # Create post with the uploaded video\n",
    "        url = f\"{self.base_url}/ugcPosts\"\n",
    "        \n",
    "        media = {\n",
    "            \"status\": \"READY\",\n",
    "            \"media\": asset_id\n",
    "        }\n",
    "        \n",
    "        if title:\n",
    "            media[\"title\"] = {\"text\": title}\n",
    "        \n",
    "        if description:\n",
    "            media[\"description\"] = {\"text\": description}\n",
    "        \n",
    "        payload = {\n",
    "            \"author\": self.person_urn,\n",
    "            \"lifecycleState\": \"PUBLISHED\",\n",
    "            \"specificContent\": {\n",
    "                \"com.linkedin.ugc.ShareContent\": {\n",
    "                    \"shareCommentary\": {\n",
    "                        \"text\": text\n",
    "                    },\n",
    "                    \"shareMediaCategory\": \"VIDEO\",\n",
    "                    \"media\": [media]\n",
    "                }\n",
    "            },\n",
    "            \"visibility\": {\n",
    "                \"com.linkedin.ugc.MemberNetworkVisibility\": visibility\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, headers=self.headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.headers.get('X-RestLi-Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Authorization': 'Bearer AQWRCKccPytjjdSx24r0pt_aoEm6TKdv7PE-zXv_aKZlScqb64Ioy5KKRoeYhn2Ur9a1GQRdutpuaQkBG7lks4Ot38eZTWjBjWMytTnDGwhOeRhLOYQsfU-eZa_eJUThDhoEdc9eAGWaE28PWNHBgXwiurOmZ6YdNoEBBMki5MzfuEUDDu4NDwVBnjL6INyfAweXihFErphvExhIiWbc_2FFR_uBeOE6Tq6OgJb9RTa14QRj3KxakgSm8Vubk3fl0YBZs7G8GSiCpGetNhS2AycPgRJGXqCeBrv5Id7-xrc8fySFgDmqf_1qMDB0AZKb2MCxNE2q-YTsqYVZ0z55WpVJY-07YQ', 'Content-Type': 'application/json', 'X-Restli-Protocol-Version': '2.0.0'}\n",
      "Error retrieving profile: 403 Client Error: Forbidden for url: https://api.linkedin.com/v2/me\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "access_token = \"AQWRCKccPytjjdSx24r0pt_aoEm6TKdv7PE-zXv_aKZlScqb64Ioy5KKRoeYhn2Ur9a1GQRdutpuaQkBG7lks4Ot38eZTWjBjWMytTnDGwhOeRhLOYQsfU-eZa_eJUThDhoEdc9eAGWaE28PWNHBgXwiurOmZ6YdNoEBBMki5MzfuEUDDu4NDwVBnjL6INyfAweXihFErphvExhIiWbc_2FFR_uBeOE6Tq6OgJb9RTa14QRj3KxakgSm8Vubk3fl0YBZs7G8GSiCpGetNhS2AycPgRJGXqCeBrv5Id7-xrc8fySFgDmqf_1qMDB0AZKb2MCxNE2q-YTsqYVZ0z55WpVJY-07YQ\"\n",
    "\n",
    "# Create an instance of LinkedInShare\n",
    "linkedin = LinkedInShare(access_token)\n",
    "\n",
    "# Debug: Print headers to verify token is properly formatted\n",
    "print(linkedin.headers)\n",
    "\n",
    "# Try a simple operation like getting your profile\n",
    "try:\n",
    "    profile = linkedin.get_profile()\n",
    "    print(\"Successfully retrieved profile:\", profile)\n",
    "except Exception as e:\n",
    "    print(\"Error retrieving profile:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AQU9ocuSvBRaOMAPcXmQTJBP-ntg0qIecfEmbL_ZIMSkibAK-ZuuHCxhajCH3AGtYIbC8gteyB8Ti8unuLlYo0hCpIWHb015-R5BgSH2b9XvP2cqaPg0FSBg7TKsqyqKy-Cm_6lqeWuennYXqbd5AZEa2NhS7zXfkV3p7QHLRAsDmbuDs7FkfKBKZi9t0q8GdoXrocHfjerlqqP1prqDxSIsWFbd2UBsOjDyEa8azISP7Cu2wywpvZCF69TOBUgbF_rDf2jETrZAREtJlv26gjn7hSde6octuWSTiZXdBnTu79ACPgI2use1kc7zzT7PMF2qftWziCIncyRgGD620fEOaovrUQ'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting profile: 403, {\"status\":403,\"serviceErrorCode\":100,\"code\":\"ACCESS_DENIED\",\"message\":\"Not enough permissions to access: me.GET.NO_VERSION\"}\n",
      "Attempting to post without profile info...\n",
      "Post attempt response: 422, {\"message\":\"ERROR :: /author :: \\\"urn:li:person:YOUR_LINKEDIN_ID\\\" does not match urn:li:company:\\\\d+|urn:li:member:\\\\d+\\n\",\"status\":422}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Try to get the person ID using the /me endpoint with specific fields\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {access_token}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"X-Restli-Protocol-Version\": \"2.0.0\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    # First try with r_basicprofile route\n",
    "    response = requests.get(\"https://api.linkedin.com/v2/me?projection=(id)\", headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        person_id = data.get('id')\n",
    "        print(f\"Successfully retrieved person ID: {person_id}\")\n",
    "    else:\n",
    "        print(f\"Error getting profile: {response.status_code}, {response.text}\")\n",
    "        print(\"Attempting to post without profile info...\")\n",
    "        \n",
    "        # Try posting without getting profile first - use a placeholder person_urn\n",
    "        # Note: You'll need to replace this with your actual LinkedIn ID if you know it\n",
    "        person_urn = \"urn:li:person:YOUR_LINKEDIN_ID\"  # Replace with your LinkedIn ID\n",
    "        \n",
    "        url = \"https://api.linkedin.com/v2/ugcPosts\"\n",
    "        payload = {\n",
    "            \"author\": person_urn,\n",
    "            \"lifecycleState\": \"PUBLISHED\",\n",
    "            \"specificContent\": {\n",
    "                \"com.linkedin.ugc.ShareContent\": {\n",
    "                    \"shareCommentary\": {\n",
    "                        \"text\": \"Testing LinkedIn API post\"\n",
    "                    },\n",
    "                    \"shareMediaCategory\": \"NONE\"\n",
    "                }\n",
    "            },\n",
    "            \"visibility\": {\n",
    "                \"com.linkedin.ugc.MemberNetworkVisibility\": \"PUBLIC\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        print(f\"Post attempt response: {response.status_code}, {response.text}\")\n",
    "except Exception as e:\n",
    "    print(f\"Exception occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "422 Client Error: Unprocessable Entity for url: https://api.linkedin.com/v2/ugcPosts",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m linkedin\u001b[38;5;241m.\u001b[39mperson_urn \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murn:li:person:gautham-balraj-b7571b243\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Now you can use the posting methods\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m post_id \u001b[38;5;241m=\u001b[39m \u001b[43mlinkedin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHello World! This is my first Share on LinkedIn!\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPost created with ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpost_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 77\u001b[0m, in \u001b[0;36mLinkedInShare.post_text\u001b[0;34m(self, text, visibility)\u001b[0m\n\u001b[1;32m     60\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperson_urn,\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlifecycleState\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPUBLISHED\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m     }\n\u001b[1;32m     74\u001b[0m }\n\u001b[1;32m     76\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(url, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders, json\u001b[38;5;241m=\u001b[39mpayload)\n\u001b[0;32m---> 77\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX-RestLi-Id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/agentic/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 422 Client Error: Unprocessable Entity for url: https://api.linkedin.com/v2/ugcPosts"
     ]
    }
   ],
   "source": [
    "# https://www.linkedin.com/in/gautham-balraj-b7571b243/\n",
    "# Initialize with your access token and member ID\n",
    "linkedin = LinkedInShare(access_token)\n",
    "\n",
    "# Set person_urn directly instead of retrieving it\n",
    "linkedin.person_urn = f\"urn:li:person:gautham-balraj-b7571b243\"\n",
    "\n",
    "# Now you can use the posting methods\n",
    "post_id = linkedin.post_text(\"Hello World! This is my first Share on LinkedIn!\")\n",
    "print(f\"Post created with ID: {post_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "class LinkedInShare:\n",
    "    \"\"\"\n",
    "    A Python wrapper for the LinkedIn Share API.\n",
    "    This class provides methods to post content to LinkedIn, including text, articles/URLs, and images/videos.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, access_token, person_urn=None):\n",
    "        \"\"\"\n",
    "        Initialize the LinkedIn API wrapper with an OAuth 2.0 access token.\n",
    "        \n",
    "        Args:\n",
    "            access_token (str): OAuth 2.0 access token with w_member_social scope\n",
    "            person_urn (str, optional): Your LinkedIn Person URN (e.g., \"urn:li:person:Hi1z4OfXkc\")\n",
    "        \"\"\"\n",
    "        self.access_token = access_token\n",
    "        self.base_url = \"https://api.linkedin.com/v2\"\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {access_token}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"X-Restli-Protocol-Version\": \"2.0.0\"\n",
    "        }\n",
    "        \n",
    "        # Use provided person URN or get it from profile\n",
    "        self.person_urn = person_urn\n",
    "    \n",
    "    def get_profile(self):\n",
    "        \"\"\"\n",
    "        Get the profile information of the authenticated user to retrieve the Person URN.\n",
    "        \n",
    "        Returns:\n",
    "            dict: Profile information\n",
    "        \"\"\"\n",
    "        url = f\"{self.base_url}/userinfo\"\n",
    "        response = requests.get(url, headers=self.headers)\n",
    "        response.raise_for_status()\n",
    "        profile_data = response.json()\n",
    "        self.person_urn = f\"urn:li:person:{profile_data['sub']}\"\n",
    "        return profile_data\n",
    "    \n",
    "    def post_text(self, text, visibility=\"PUBLIC\"):\n",
    "        \"\"\"\n",
    "        Create a simple text post on LinkedIn.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The text content of the post\n",
    "            visibility (str): Visibility of the post, either \"PUBLIC\" or \"CONNECTIONS\"\n",
    "            \n",
    "        Returns:\n",
    "            dict: Response from the API including status code and headers\n",
    "        \"\"\"\n",
    "        if not self.person_urn:\n",
    "            raise ValueError(\"Person URN is required. Either provide it during initialization or call get_profile() first.\")\n",
    "            \n",
    "        url = f\"{self.base_url}/ugcPosts\"\n",
    "        \n",
    "        payload = {\n",
    "            \"author\": self.person_urn,\n",
    "            \"lifecycleState\": \"PUBLISHED\",\n",
    "            \"specificContent\": {\n",
    "                \"com.linkedin.ugc.ShareContent\": {\n",
    "                    \"shareCommentary\": {\n",
    "                        \"text\": text\n",
    "                    },\n",
    "                    \"shareMediaCategory\": \"NONE\"\n",
    "                }\n",
    "            },\n",
    "            \"visibility\": {\n",
    "                \"com.linkedin.ugc.MemberNetworkVisibility\": visibility\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, headers=self.headers, json=payload)\n",
    "        result = {\n",
    "            \"status_code\": response.status_code,\n",
    "            \"headers\": dict(response.headers),\n",
    "            \"post_id\": response.headers.get('X-RestLi-Id') if response.status_code == 201 else None\n",
    "        }\n",
    "        \n",
    "        if response.status_code != 201:\n",
    "            result[\"error\"] = response.text\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def post_article(self, text, article_url, title=None, description=None, visibility=\"PUBLIC\"):\n",
    "        \"\"\"\n",
    "        Create a post with an article or URL on LinkedIn.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The text content of the post\n",
    "            article_url (str): URL to share\n",
    "            title (str, optional): Custom title for the article\n",
    "            description (str, optional): Custom description for the article\n",
    "            visibility (str): Visibility of the post, either \"PUBLIC\" or \"CONNECTIONS\"\n",
    "            \n",
    "        Returns:\n",
    "            dict: Response from the API including status code and headers\n",
    "        \"\"\"\n",
    "        if not self.person_urn:\n",
    "            raise ValueError(\"Person URN is required. Either provide it during initialization or call get_profile() first.\")\n",
    "            \n",
    "        url = f\"{self.base_url}/ugcPosts\"\n",
    "        \n",
    "        media = {\n",
    "            \"status\": \"READY\",\n",
    "            \"originalUrl\": article_url\n",
    "        }\n",
    "        \n",
    "        if title:\n",
    "            media[\"title\"] = {\"text\": title}\n",
    "        \n",
    "        if description:\n",
    "            media[\"description\"] = {\"text\": description}\n",
    "        \n",
    "        payload = {\n",
    "            \"author\": self.person_urn,\n",
    "            \"lifecycleState\": \"PUBLISHED\",\n",
    "            \"specificContent\": {\n",
    "                \"com.linkedin.ugc.ShareContent\": {\n",
    "                    \"shareCommentary\": {\n",
    "                        \"text\": text\n",
    "                    },\n",
    "                    \"shareMediaCategory\": \"ARTICLE\",\n",
    "                    \"media\": [media]\n",
    "                }\n",
    "            },\n",
    "            \"visibility\": {\n",
    "                \"com.linkedin.ugc.MemberNetworkVisibility\": visibility\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, headers=self.headers, json=payload)\n",
    "        result = {\n",
    "            \"status_code\": response.status_code,\n",
    "            \"headers\": dict(response.headers),\n",
    "            \"post_id\": response.headers.get('X-RestLi-Id') if response.status_code == 201 else None\n",
    "        }\n",
    "        \n",
    "        if response.status_code != 201:\n",
    "            result[\"error\"] = response.text\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def register_upload(self, media_type=\"image\"):\n",
    "        \"\"\"\n",
    "        Register an image or video upload with LinkedIn.\n",
    "        \n",
    "        Args:\n",
    "            media_type (str): Either \"image\" or \"video\"\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (upload_url, asset_id) or None if registration fails\n",
    "        \"\"\"\n",
    "        if not self.person_urn:\n",
    "            raise ValueError(\"Person URN is required. Either provide it during initialization or call get_profile() first.\")\n",
    "            \n",
    "        url = f\"{self.base_url}/assets?action=registerUpload\"\n",
    "        \n",
    "        recipe = \"urn:li:digitalmediaRecipe:feedshare-image\" if media_type == \"image\" else \"urn:li:digitalmediaRecipe:feedshare-video\"\n",
    "        \n",
    "        payload = {\n",
    "            \"registerUploadRequest\": {\n",
    "                \"recipes\": [recipe],\n",
    "                \"owner\": self.person_urn,\n",
    "                \"serviceRelationships\": [\n",
    "                    {\n",
    "                        \"relationshipType\": \"OWNER\",\n",
    "                        \"identifier\": \"urn:li:userGeneratedContent\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, headers=self.headers, json=payload)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error registering upload: {response.status_code}\")\n",
    "            print(response.text)\n",
    "            return None\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        try:\n",
    "            upload_url = data[\"value\"][\"uploadMechanism\"][\"com.linkedin.digitalmedia.uploading.MediaUploadHttpRequest\"][\"uploadUrl\"]\n",
    "            asset_id = data[\"value\"][\"asset\"]\n",
    "            return upload_url, asset_id\n",
    "        except KeyError as e:\n",
    "            print(f\"Unexpected response format: {e}\")\n",
    "            print(data)\n",
    "            return None\n",
    "    \n",
    "    def upload_media(self, upload_url, file_path):\n",
    "        \"\"\"\n",
    "        Upload an image or video file to LinkedIn.\n",
    "        \n",
    "        Args:\n",
    "            upload_url (str): URL obtained from register_upload\n",
    "            file_path (str): Path to the local image or video file\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if upload was successful\n",
    "        \"\"\"\n",
    "        with open(file_path, 'rb') as file:\n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {self.access_token}\"\n",
    "            }\n",
    "            response = requests.post(upload_url, headers=headers, data=file)\n",
    "            \n",
    "            if response.status_code >= 200 and response.status_code < 300:\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"Error uploading media: {response.status_code}\")\n",
    "                print(response.text)\n",
    "                return False\n",
    "    \n",
    "    def post_image(self, text, image_path, title=None, description=None, visibility=\"PUBLIC\"):\n",
    "        \"\"\"\n",
    "        Create a post with an image on LinkedIn.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The text content of the post\n",
    "            image_path (str): Path to the local image file\n",
    "            title (str, optional): Custom title for the image\n",
    "            description (str, optional): Custom description for the image\n",
    "            visibility (str): Visibility of the post, either \"PUBLIC\" or \"CONNECTIONS\"\n",
    "            \n",
    "        Returns:\n",
    "            dict: Response from the API including status code and headers\n",
    "        \"\"\"\n",
    "        if not self.person_urn:\n",
    "            raise ValueError(\"Person URN is required. Either provide it during initialization or call get_profile() first.\")\n",
    "            \n",
    "        # Register upload\n",
    "        upload_result = self.register_upload(media_type=\"image\")\n",
    "        if not upload_result:\n",
    "            return {\"status_code\": 500, \"error\": \"Failed to register image upload\"}\n",
    "        \n",
    "        upload_url, asset_id = upload_result\n",
    "        \n",
    "        # Upload image\n",
    "        upload_success = self.upload_media(upload_url, image_path)\n",
    "        if not upload_success:\n",
    "            return {\"status_code\": 500, \"error\": \"Failed to upload image\"}\n",
    "        \n",
    "        # Create post with the uploaded image\n",
    "        url = f\"{self.base_url}/ugcPosts\"\n",
    "        \n",
    "        media = {\n",
    "            \"status\": \"READY\",\n",
    "            \"media\": asset_id\n",
    "        }\n",
    "        \n",
    "        if title:\n",
    "            media[\"title\"] = {\"text\": title}\n",
    "        \n",
    "        if description:\n",
    "            media[\"description\"] = {\"text\": description}\n",
    "        \n",
    "        payload = {\n",
    "            \"author\": self.person_urn,\n",
    "            \"lifecycleState\": \"PUBLISHED\",\n",
    "            \"specificContent\": {\n",
    "                \"com.linkedin.ugc.ShareContent\": {\n",
    "                    \"shareCommentary\": {\n",
    "                        \"text\": text\n",
    "                    },\n",
    "                    \"shareMediaCategory\": \"IMAGE\",\n",
    "                    \"media\": [media]\n",
    "                }\n",
    "            },\n",
    "            \"visibility\": {\n",
    "                \"com.linkedin.ugc.MemberNetworkVisibility\": visibility\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, headers=self.headers, json=payload)\n",
    "        result = {\n",
    "            \"status_code\": response.status_code,\n",
    "            \"headers\": dict(response.headers),\n",
    "            \"post_id\": response.headers.get('X-RestLi-Id') if response.status_code == 201 else None\n",
    "        }\n",
    "        \n",
    "        if response.status_code != 201:\n",
    "            result[\"error\"] = response.text\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def post_video(self, text, video_path, title=None, description=None, visibility=\"PUBLIC\"):\n",
    "        \"\"\"\n",
    "        Create a post with a video on LinkedIn.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The text content of the post\n",
    "            video_path (str): Path to the local video file\n",
    "            title (str, optional): Custom title for the video\n",
    "            description (str, optional): Custom description for the video\n",
    "            visibility (str): Visibility of the post, either \"PUBLIC\" or \"CONNECTIONS\"\n",
    "            \n",
    "        Returns:\n",
    "            dict: Response from the API including status code and headers\n",
    "        \"\"\"\n",
    "        if not self.person_urn:\n",
    "            raise ValueError(\"Person URN is required. Either provide it during initialization or call get_profile() first.\")\n",
    "            \n",
    "        # Register upload\n",
    "        upload_result = self.register_upload(media_type=\"video\")\n",
    "        if not upload_result:\n",
    "            return {\"status_code\": 500, \"error\": \"Failed to register video upload\"}\n",
    "        \n",
    "        upload_url, asset_id = upload_result\n",
    "        \n",
    "        # Upload video\n",
    "        upload_success = self.upload_media(upload_url, video_path)\n",
    "        if not upload_success:\n",
    "            return {\"status_code\": 500, \"error\": \"Failed to upload video\"}\n",
    "        \n",
    "        # Create post with the uploaded video\n",
    "        url = f\"{self.base_url}/ugcPosts\"\n",
    "        \n",
    "        media = {\n",
    "            \"status\": \"READY\",\n",
    "            \"media\": asset_id\n",
    "        }\n",
    "        \n",
    "        if title:\n",
    "            media[\"title\"] = {\"text\": title}\n",
    "        \n",
    "        if description:\n",
    "            media[\"description\"] = {\"text\": description}\n",
    "        \n",
    "        payload = {\n",
    "            \"author\": self.person_urn,\n",
    "            \"lifecycleState\": \"PUBLISHED\",\n",
    "            \"specificContent\": {\n",
    "                \"com.linkedin.ugc.ShareContent\": {\n",
    "                    \"shareCommentary\": {\n",
    "                        \"text\": text\n",
    "                    },\n",
    "                    \"shareMediaCategory\": \"VIDEO\",\n",
    "                    \"media\": [media]\n",
    "                }\n",
    "            },\n",
    "            \"visibility\": {\n",
    "                \"com.linkedin.ugc.MemberNetworkVisibility\": visibility\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, headers=self.headers, json=payload)\n",
    "        result = {\n",
    "            \"status_code\": response.status_code,\n",
    "            \"headers\": dict(response.headers),\n",
    "            \"post_id\": response.headers.get('X-RestLi-Id') if response.status_code == 201 else None\n",
    "        }\n",
    "        \n",
    "        if response.status_code != 201:\n",
    "            result[\"error\"] = response.text\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 422\n",
      "Error creating post: {\"message\":\"ERROR :: /visibility/com.linkedin.ugc.MemberNetworkVisibility :: \\\"PRIVATE\\\" is not an enum symbol\\n\",\"status\":422}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "person_urn = \"urn:li:person:Hi1z4OfXkc\"  # Use your actual person URN\n",
    "\n",
    "# Create the LinkedIn client\n",
    "linkedin = LinkedInShare(access_token, person_urn)\n",
    "\n",
    "# Example 1: Post a simple text update (matching your Postman example)\n",
    "result = linkedin.post_text(\n",
    "    text=\"Test - automation (sm_agent) workingg\",\n",
    "    visibility=\"PRIVATE\"\n",
    ")\n",
    "\n",
    "print(f\"Status code: {result['status_code']}\")\n",
    "if result['status_code'] == 201:\n",
    "    print(f\"Post created successfully! Post ID: {result['post_id']}\")\n",
    "else:\n",
    "    print(f\"Error creating post: {result.get('error', 'Unknown error')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mRunning function: graph_builder\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.assistant.graph import graph_builder\n",
    "from src.assistant.state import SummaryState\n",
    "from langgraph.types import interrupt, Command\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "graph = graph_builder()\n",
    "topic = \"Gemma 3\"\n",
    "summary_state = SummaryState(\n",
    "    research_topic=topic,\n",
    "    search_query='',\n",
    "    web_research_results=[],\n",
    "    sources_gathered=[],\n",
    "    research_loop_count=0,\n",
    "    running_summary=None,\n",
    "    tweets=[]\n",
    ")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'research_topic': 'Gemma 3', 'web_research_results': [], 'sources_gathered': [], 'tweets': [], 'linkedin_posts': []}\n",
      "\u001b[94mRunning function: generate_query - 0 \u001b[0m\n",
      "{'research_topic': 'Gemma 3', 'search_query': 'Gemma 3 satellite mission', 'web_research_results': [], 'sources_gathered': [], 'tweets': [], 'linkedin_posts': []}\n",
      "\u001b[94mRunning function: web_search\u001b[0m\n",
      "\u001b[94mRunning function: generate_query - 0 \u001b[0m\n",
      "{'research_topic': 'Gemma 3', 'search_query': 'Gemma 3 satellite mission', 'web_research_results': [\"Query: Gemma 3 satellite mission\\nSearch Results:\\n\\n1. Gemma 3: Google's new open model based on Gemini 2.0\\n   URL: https://blog.google/technology/developers/gemma-3/\\n   Relevance Score: 0.25014767\\n\\n   Content: Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.\\n\\n2. Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\\n   URL: https://simonw.substack.com/p/notes-on-googles-gemma-3\\n   Relevance Score: 0.21688144\\n\\n   Content: Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands\\n\\n3. Google calls Gemma 3 the most powerful AI model you can run on ...\\n   URL: https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model\\n   Relevance Score: 0.16514862\\n\\n   Content: Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.\\n\\n4. Introducing Gemma 3: The Developer Guide\\n   URL: https://developers.googleblog.com/en/introducing-gemma3/\\n   Relevance Score: 0.15816164\\n\\n   Content: Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025\\n\\n5. Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube\\n   URL: https://www.youtube.com/watch?v=rMSSuY4ppnY\\n   Relevance Score: 0.13856693\\n\\n   Content: Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\\n\"], 'sources_gathered': [{'url': 'https://blog.google/technology/developers/gemma-3/', 'title': \"Gemma 3: Google's new open model based on Gemini 2.0\", 'content': 'Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.', 'score': 0.25014767, 'raw_content': None}, {'url': 'https://simonw.substack.com/p/notes-on-googles-gemma-3', 'title': \"Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\", 'content': 'Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands', 'score': 0.21688144, 'raw_content': None}, {'url': 'https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model', 'title': 'Google calls Gemma 3 the most powerful AI model you can run on ...', 'content': 'Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.', 'score': 0.16514862, 'raw_content': None}, {'url': 'https://developers.googleblog.com/en/introducing-gemma3/', 'title': 'Introducing Gemma 3: The Developer Guide', 'content': 'Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025', 'score': 0.15816164, 'raw_content': None}, {'url': 'https://www.youtube.com/watch?v=rMSSuY4ppnY', 'title': 'Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube', 'content': \"Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\", 'score': 0.13856693, 'raw_content': None}], 'research_loop_count': 1, 'tweets': [], 'linkedin_posts': []}\n",
      "\u001b[94mRunning function: summarizer\u001b[0m\n",
      "{'research_topic': 'Gemma 3', 'search_query': 'Gemma 3 satellite mission', 'web_research_results': [\"Query: Gemma 3 satellite mission\\nSearch Results:\\n\\n1. Gemma 3: Google's new open model based on Gemini 2.0\\n   URL: https://blog.google/technology/developers/gemma-3/\\n   Relevance Score: 0.25014767\\n\\n   Content: Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.\\n\\n2. Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\\n   URL: https://simonw.substack.com/p/notes-on-googles-gemma-3\\n   Relevance Score: 0.21688144\\n\\n   Content: Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands\\n\\n3. Google calls Gemma 3 the most powerful AI model you can run on ...\\n   URL: https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model\\n   Relevance Score: 0.16514862\\n\\n   Content: Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.\\n\\n4. Introducing Gemma 3: The Developer Guide\\n   URL: https://developers.googleblog.com/en/introducing-gemma3/\\n   Relevance Score: 0.15816164\\n\\n   Content: Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025\\n\\n5. Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube\\n   URL: https://www.youtube.com/watch?v=rMSSuY4ppnY\\n   Relevance Score: 0.13856693\\n\\n   Content: Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\\n\"], 'sources_gathered': [{'url': 'https://blog.google/technology/developers/gemma-3/', 'title': \"Gemma 3: Google's new open model based on Gemini 2.0\", 'content': 'Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.', 'score': 0.25014767, 'raw_content': None}, {'url': 'https://simonw.substack.com/p/notes-on-googles-gemma-3', 'title': \"Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\", 'content': 'Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands', 'score': 0.21688144, 'raw_content': None}, {'url': 'https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model', 'title': 'Google calls Gemma 3 the most powerful AI model you can run on ...', 'content': 'Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.', 'score': 0.16514862, 'raw_content': None}, {'url': 'https://developers.googleblog.com/en/introducing-gemma3/', 'title': 'Introducing Gemma 3: The Developer Guide', 'content': 'Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025', 'score': 0.15816164, 'raw_content': None}, {'url': 'https://www.youtube.com/watch?v=rMSSuY4ppnY', 'title': 'Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube', 'content': \"Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\", 'score': 0.13856693, 'raw_content': None}], 'research_loop_count': 1, 'running_summary': 'Gemma 3 is Google\\'s new open model based on Gemini 2.0, designed to make useful AI technology accessible. It introduces multimodality, supporting vision-language input and text outputs, and handles context windows up to 128k tokens. The model is optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm stack. Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, and local environments, giving developers flexibility in choosing the best fit for their application and infrastructure.\\n\\nThe model uses a new tokenizer for better multilingual support, covering over 140 languages, and was trained on large datasets using the JAX Framework. Gemma 3 is considered the most powerful AI model that can run on one GPU, and its popularity indicates interest in AI technology with lower hardware requirements. However, the definition of an \"open\" or \"open source\" AI model remains a topic of debate, with Google\\'s license restricting usage.\\n\\nGemma 3 provides various tools and integrations, including support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, and Gemma.cpp, allowing developers to choose their preferred tools. The model is also compatible with Google AI Edge, enabling deployment on mobile and web platforms. Additionally, Gemma 3 has been compared to other models, such as QwQ and Deepseek R1 671b, with some considering it the best open-source vision model. Overall, Gemma 3 aims to accelerate AI development across multiple hardware platforms, making it a significant release in the field of artificial intelligence.', 'tweets': [], 'linkedin_posts': []}\n",
      "\u001b[94mRunning function: reflection\u001b[0m\n",
      "\u001b[94mRunning function: route_research\u001b[0m\n",
      "{'research_topic': 'Gemma 3', 'search_query': 'Gemma 3 tokenizer architecture and comparison with existing tokenization methods for multilingual support in AI models', 'web_research_results': [\"Query: Gemma 3 satellite mission\\nSearch Results:\\n\\n1. Gemma 3: Google's new open model based on Gemini 2.0\\n   URL: https://blog.google/technology/developers/gemma-3/\\n   Relevance Score: 0.25014767\\n\\n   Content: Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.\\n\\n2. Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\\n   URL: https://simonw.substack.com/p/notes-on-googles-gemma-3\\n   Relevance Score: 0.21688144\\n\\n   Content: Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands\\n\\n3. Google calls Gemma 3 the most powerful AI model you can run on ...\\n   URL: https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model\\n   Relevance Score: 0.16514862\\n\\n   Content: Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.\\n\\n4. Introducing Gemma 3: The Developer Guide\\n   URL: https://developers.googleblog.com/en/introducing-gemma3/\\n   Relevance Score: 0.15816164\\n\\n   Content: Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025\\n\\n5. Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube\\n   URL: https://www.youtube.com/watch?v=rMSSuY4ppnY\\n   Relevance Score: 0.13856693\\n\\n   Content: Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\\n\"], 'sources_gathered': [{'url': 'https://blog.google/technology/developers/gemma-3/', 'title': \"Gemma 3: Google's new open model based on Gemini 2.0\", 'content': 'Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.', 'score': 0.25014767, 'raw_content': None}, {'url': 'https://simonw.substack.com/p/notes-on-googles-gemma-3', 'title': \"Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\", 'content': 'Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands', 'score': 0.21688144, 'raw_content': None}, {'url': 'https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model', 'title': 'Google calls Gemma 3 the most powerful AI model you can run on ...', 'content': 'Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.', 'score': 0.16514862, 'raw_content': None}, {'url': 'https://developers.googleblog.com/en/introducing-gemma3/', 'title': 'Introducing Gemma 3: The Developer Guide', 'content': 'Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025', 'score': 0.15816164, 'raw_content': None}, {'url': 'https://www.youtube.com/watch?v=rMSSuY4ppnY', 'title': 'Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube', 'content': \"Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\", 'score': 0.13856693, 'raw_content': None}], 'research_loop_count': 1, 'running_summary': 'Gemma 3 is Google\\'s new open model based on Gemini 2.0, designed to make useful AI technology accessible. It introduces multimodality, supporting vision-language input and text outputs, and handles context windows up to 128k tokens. The model is optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm stack. Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, and local environments, giving developers flexibility in choosing the best fit for their application and infrastructure.\\n\\nThe model uses a new tokenizer for better multilingual support, covering over 140 languages, and was trained on large datasets using the JAX Framework. Gemma 3 is considered the most powerful AI model that can run on one GPU, and its popularity indicates interest in AI technology with lower hardware requirements. However, the definition of an \"open\" or \"open source\" AI model remains a topic of debate, with Google\\'s license restricting usage.\\n\\nGemma 3 provides various tools and integrations, including support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, and Gemma.cpp, allowing developers to choose their preferred tools. The model is also compatible with Google AI Edge, enabling deployment on mobile and web platforms. Additionally, Gemma 3 has been compared to other models, such as QwQ and Deepseek R1 671b, with some considering it the best open-source vision model. Overall, Gemma 3 aims to accelerate AI development across multiple hardware platforms, making it a significant release in the field of artificial intelligence.', 'tweets': [], 'linkedin_posts': []}\n",
      "\u001b[94mRunning function: web_search\u001b[0m\n",
      "\u001b[94mRunning function: generate_query - 1 \u001b[0m\n",
      "{'research_topic': 'Gemma 3', 'search_query': 'Gemma 3 tokenizer architecture and comparison with existing tokenization methods for multilingual support in AI models', 'web_research_results': [\"Query: Gemma 3 satellite mission\\nSearch Results:\\n\\n1. Gemma 3: Google's new open model based on Gemini 2.0\\n   URL: https://blog.google/technology/developers/gemma-3/\\n   Relevance Score: 0.25014767\\n\\n   Content: Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.\\n\\n2. Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\\n   URL: https://simonw.substack.com/p/notes-on-googles-gemma-3\\n   Relevance Score: 0.21688144\\n\\n   Content: Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands\\n\\n3. Google calls Gemma 3 the most powerful AI model you can run on ...\\n   URL: https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model\\n   Relevance Score: 0.16514862\\n\\n   Content: Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.\\n\\n4. Introducing Gemma 3: The Developer Guide\\n   URL: https://developers.googleblog.com/en/introducing-gemma3/\\n   Relevance Score: 0.15816164\\n\\n   Content: Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025\\n\\n5. Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube\\n   URL: https://www.youtube.com/watch?v=rMSSuY4ppnY\\n   Relevance Score: 0.13856693\\n\\n   Content: Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\\n\", \"Query: Gemma 3 satellite mission\\nSearch Results:\\n\\n1. Gemma 3: Google's new open model based on Gemini 2.0\\n   URL: https://blog.google/technology/developers/gemma-3/\\n   Relevance Score: 0.25014767\\n\\n   Content: Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.\\n\\n2. Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\\n   URL: https://simonw.substack.com/p/notes-on-googles-gemma-3\\n   Relevance Score: 0.21688144\\n\\n   Content: Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands\\n\\n3. Google calls Gemma 3 the most powerful AI model you can run on ...\\n   URL: https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model\\n   Relevance Score: 0.16514862\\n\\n   Content: Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.\\n\\n4. Introducing Gemma 3: The Developer Guide\\n   URL: https://developers.googleblog.com/en/introducing-gemma3/\\n   Relevance Score: 0.15816164\\n\\n   Content: Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025\\n\\n5. Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube\\n   URL: https://www.youtube.com/watch?v=rMSSuY4ppnY\\n   Relevance Score: 0.13856693\\n\\n   Content: Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\\n\"], 'sources_gathered': [{'url': 'https://blog.google/technology/developers/gemma-3/', 'title': \"Gemma 3: Google's new open model based on Gemini 2.0\", 'content': 'Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.', 'score': 0.25014767, 'raw_content': None}, {'url': 'https://simonw.substack.com/p/notes-on-googles-gemma-3', 'title': \"Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\", 'content': 'Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands', 'score': 0.21688144, 'raw_content': None}, {'url': 'https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model', 'title': 'Google calls Gemma 3 the most powerful AI model you can run on ...', 'content': 'Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.', 'score': 0.16514862, 'raw_content': None}, {'url': 'https://developers.googleblog.com/en/introducing-gemma3/', 'title': 'Introducing Gemma 3: The Developer Guide', 'content': 'Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025', 'score': 0.15816164, 'raw_content': None}, {'url': 'https://www.youtube.com/watch?v=rMSSuY4ppnY', 'title': 'Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube', 'content': \"Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\", 'score': 0.13856693, 'raw_content': None}, {'url': 'https://blog.google/technology/developers/gemma-3/', 'title': \"Gemma 3: Google's new open model based on Gemini 2.0\", 'content': 'Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.', 'score': 0.25014767, 'raw_content': None}, {'url': 'https://simonw.substack.com/p/notes-on-googles-gemma-3', 'title': \"Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\", 'content': 'Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands', 'score': 0.21688144, 'raw_content': None}, {'url': 'https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model', 'title': 'Google calls Gemma 3 the most powerful AI model you can run on ...', 'content': 'Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.', 'score': 0.16514862, 'raw_content': None}, {'url': 'https://developers.googleblog.com/en/introducing-gemma3/', 'title': 'Introducing Gemma 3: The Developer Guide', 'content': 'Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025', 'score': 0.15816164, 'raw_content': None}, {'url': 'https://www.youtube.com/watch?v=rMSSuY4ppnY', 'title': 'Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube', 'content': \"Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\", 'score': 0.13856693, 'raw_content': None}], 'research_loop_count': 2, 'running_summary': 'Gemma 3 is Google\\'s new open model based on Gemini 2.0, designed to make useful AI technology accessible. It introduces multimodality, supporting vision-language input and text outputs, and handles context windows up to 128k tokens. The model is optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm stack. Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, and local environments, giving developers flexibility in choosing the best fit for their application and infrastructure.\\n\\nThe model uses a new tokenizer for better multilingual support, covering over 140 languages, and was trained on large datasets using the JAX Framework. Gemma 3 is considered the most powerful AI model that can run on one GPU, and its popularity indicates interest in AI technology with lower hardware requirements. However, the definition of an \"open\" or \"open source\" AI model remains a topic of debate, with Google\\'s license restricting usage.\\n\\nGemma 3 provides various tools and integrations, including support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, and Gemma.cpp, allowing developers to choose their preferred tools. The model is also compatible with Google AI Edge, enabling deployment on mobile and web platforms. Additionally, Gemma 3 has been compared to other models, such as QwQ and Deepseek R1 671b, with some considering it the best open-source vision model. Overall, Gemma 3 aims to accelerate AI development across multiple hardware platforms, making it a significant release in the field of artificial intelligence.', 'tweets': [], 'linkedin_posts': []}\n",
      "\u001b[94mRunning function: summarizer\u001b[0m\n",
      "{'research_topic': 'Gemma 3', 'search_query': 'Gemma 3 tokenizer architecture and comparison with existing tokenization methods for multilingual support in AI models', 'web_research_results': [\"Query: Gemma 3 satellite mission\\nSearch Results:\\n\\n1. Gemma 3: Google's new open model based on Gemini 2.0\\n   URL: https://blog.google/technology/developers/gemma-3/\\n   Relevance Score: 0.25014767\\n\\n   Content: Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.\\n\\n2. Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\\n   URL: https://simonw.substack.com/p/notes-on-googles-gemma-3\\n   Relevance Score: 0.21688144\\n\\n   Content: Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands\\n\\n3. Google calls Gemma 3 the most powerful AI model you can run on ...\\n   URL: https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model\\n   Relevance Score: 0.16514862\\n\\n   Content: Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.\\n\\n4. Introducing Gemma 3: The Developer Guide\\n   URL: https://developers.googleblog.com/en/introducing-gemma3/\\n   Relevance Score: 0.15816164\\n\\n   Content: Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025\\n\\n5. Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube\\n   URL: https://www.youtube.com/watch?v=rMSSuY4ppnY\\n   Relevance Score: 0.13856693\\n\\n   Content: Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\\n\", \"Query: Gemma 3 satellite mission\\nSearch Results:\\n\\n1. Gemma 3: Google's new open model based on Gemini 2.0\\n   URL: https://blog.google/technology/developers/gemma-3/\\n   Relevance Score: 0.25014767\\n\\n   Content: Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.\\n\\n2. Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\\n   URL: https://simonw.substack.com/p/notes-on-googles-gemma-3\\n   Relevance Score: 0.21688144\\n\\n   Content: Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands\\n\\n3. Google calls Gemma 3 the most powerful AI model you can run on ...\\n   URL: https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model\\n   Relevance Score: 0.16514862\\n\\n   Content: Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.\\n\\n4. Introducing Gemma 3: The Developer Guide\\n   URL: https://developers.googleblog.com/en/introducing-gemma3/\\n   Relevance Score: 0.15816164\\n\\n   Content: Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025\\n\\n5. Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube\\n   URL: https://www.youtube.com/watch?v=rMSSuY4ppnY\\n   Relevance Score: 0.13856693\\n\\n   Content: Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\\n\"], 'sources_gathered': [{'url': 'https://blog.google/technology/developers/gemma-3/', 'title': \"Gemma 3: Google's new open model based on Gemini 2.0\", 'content': 'Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.', 'score': 0.25014767, 'raw_content': None}, {'url': 'https://simonw.substack.com/p/notes-on-googles-gemma-3', 'title': \"Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\", 'content': 'Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands', 'score': 0.21688144, 'raw_content': None}, {'url': 'https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model', 'title': 'Google calls Gemma 3 the most powerful AI model you can run on ...', 'content': 'Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.', 'score': 0.16514862, 'raw_content': None}, {'url': 'https://developers.googleblog.com/en/introducing-gemma3/', 'title': 'Introducing Gemma 3: The Developer Guide', 'content': 'Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025', 'score': 0.15816164, 'raw_content': None}, {'url': 'https://www.youtube.com/watch?v=rMSSuY4ppnY', 'title': 'Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube', 'content': \"Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\", 'score': 0.13856693, 'raw_content': None}, {'url': 'https://blog.google/technology/developers/gemma-3/', 'title': \"Gemma 3: Google's new open model based on Gemini 2.0\", 'content': 'Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.', 'score': 0.25014767, 'raw_content': None}, {'url': 'https://simonw.substack.com/p/notes-on-googles-gemma-3', 'title': \"Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\", 'content': 'Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands', 'score': 0.21688144, 'raw_content': None}, {'url': 'https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model', 'title': 'Google calls Gemma 3 the most powerful AI model you can run on ...', 'content': 'Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.', 'score': 0.16514862, 'raw_content': None}, {'url': 'https://developers.googleblog.com/en/introducing-gemma3/', 'title': 'Introducing Gemma 3: The Developer Guide', 'content': 'Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025', 'score': 0.15816164, 'raw_content': None}, {'url': 'https://www.youtube.com/watch?v=rMSSuY4ppnY', 'title': 'Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube', 'content': \"Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\", 'score': 0.13856693, 'raw_content': None}], 'research_loop_count': 2, 'running_summary': 'Gemma 3 is Google\\'s new open model based on Gemini 2.0, designed to make useful AI technology accessible. It introduces multimodality, supporting vision-language input and text outputs, and handles context windows up to 128k tokens. The model is optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm stack. Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, and local environments, giving developers flexibility in choosing the best fit for their application and infrastructure.\\n\\nThe model uses a new tokenizer for better multilingual support, covering over 140 languages, and was trained on large datasets using the JAX Framework. Gemma 3 is considered the most powerful AI model that can run on one GPU, and its popularity indicates interest in AI technology with lower hardware requirements. However, the definition of an \"open\" or \"open source\" AI model remains a topic of debate, with Google\\'s license restricting usage.\\n\\nGemma 3 provides various tools and integrations, including support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, and Gemma.cpp, allowing developers to choose their preferred tools. The model is also compatible with Google AI Edge, enabling deployment on mobile and web platforms. Additionally, Gemma 3 has been compared to other models, such as QwQ and Deepseek R1 671b, with some considering it the best open-source vision model. \\n\\nFurthermore, Gemma 3 was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework, demonstrating its extensive training dataset. The model\\'s performance and capabilities have been discussed in various online forums and tutorials, including a developer guide and YouTube videos, which provide insights into its potential applications and limitations. Overall, Gemma 3 aims to accelerate AI development across multiple hardware platforms, making it a significant release in the field of artificial intelligence. \\n\\nThere is no information available on a Gemma 3 satellite mission, suggesting that the term \"Gemma 3\" is primarily associated with Google\\'s AI model. The search results do not provide any evidence of a satellite mission with this name, and the focus remains on the AI model\\'s features, capabilities, and potential applications.', 'tweets': [], 'linkedin_posts': []}\n",
      "\u001b[94mRunning function: reflection\u001b[0m\n",
      "\u001b[94mRunning function: route_research\u001b[0m\n",
      "{'research_topic': 'Gemma 3', 'search_query': 'Gemma 3 tokenizer architecture and performance comparison with other multilingual tokenizers like BERT and XLNet', 'web_research_results': [\"Query: Gemma 3 satellite mission\\nSearch Results:\\n\\n1. Gemma 3: Google's new open model based on Gemini 2.0\\n   URL: https://blog.google/technology/developers/gemma-3/\\n   Relevance Score: 0.25014767\\n\\n   Content: Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.\\n\\n2. Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\\n   URL: https://simonw.substack.com/p/notes-on-googles-gemma-3\\n   Relevance Score: 0.21688144\\n\\n   Content: Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands\\n\\n3. Google calls Gemma 3 the most powerful AI model you can run on ...\\n   URL: https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model\\n   Relevance Score: 0.16514862\\n\\n   Content: Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.\\n\\n4. Introducing Gemma 3: The Developer Guide\\n   URL: https://developers.googleblog.com/en/introducing-gemma3/\\n   Relevance Score: 0.15816164\\n\\n   Content: Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025\\n\\n5. Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube\\n   URL: https://www.youtube.com/watch?v=rMSSuY4ppnY\\n   Relevance Score: 0.13856693\\n\\n   Content: Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\\n\", \"Query: Gemma 3 satellite mission\\nSearch Results:\\n\\n1. Gemma 3: Google's new open model based on Gemini 2.0\\n   URL: https://blog.google/technology/developers/gemma-3/\\n   Relevance Score: 0.25014767\\n\\n   Content: Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.\\n\\n2. Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\\n   URL: https://simonw.substack.com/p/notes-on-googles-gemma-3\\n   Relevance Score: 0.21688144\\n\\n   Content: Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands\\n\\n3. Google calls Gemma 3 the most powerful AI model you can run on ...\\n   URL: https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model\\n   Relevance Score: 0.16514862\\n\\n   Content: Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.\\n\\n4. Introducing Gemma 3: The Developer Guide\\n   URL: https://developers.googleblog.com/en/introducing-gemma3/\\n   Relevance Score: 0.15816164\\n\\n   Content: Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025\\n\\n5. Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube\\n   URL: https://www.youtube.com/watch?v=rMSSuY4ppnY\\n   Relevance Score: 0.13856693\\n\\n   Content: Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\\n\"], 'sources_gathered': [{'url': 'https://blog.google/technology/developers/gemma-3/', 'title': \"Gemma 3: Google's new open model based on Gemini 2.0\", 'content': 'Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.', 'score': 0.25014767, 'raw_content': None}, {'url': 'https://simonw.substack.com/p/notes-on-googles-gemma-3', 'title': \"Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\", 'content': 'Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands', 'score': 0.21688144, 'raw_content': None}, {'url': 'https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model', 'title': 'Google calls Gemma 3 the most powerful AI model you can run on ...', 'content': 'Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.', 'score': 0.16514862, 'raw_content': None}, {'url': 'https://developers.googleblog.com/en/introducing-gemma3/', 'title': 'Introducing Gemma 3: The Developer Guide', 'content': 'Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025', 'score': 0.15816164, 'raw_content': None}, {'url': 'https://www.youtube.com/watch?v=rMSSuY4ppnY', 'title': 'Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube', 'content': \"Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\", 'score': 0.13856693, 'raw_content': None}, {'url': 'https://blog.google/technology/developers/gemma-3/', 'title': \"Gemma 3: Google's new open model based on Gemini 2.0\", 'content': 'Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.', 'score': 0.25014767, 'raw_content': None}, {'url': 'https://simonw.substack.com/p/notes-on-googles-gemma-3', 'title': \"Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\", 'content': 'Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands', 'score': 0.21688144, 'raw_content': None}, {'url': 'https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model', 'title': 'Google calls Gemma 3 the most powerful AI model you can run on ...', 'content': 'Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.', 'score': 0.16514862, 'raw_content': None}, {'url': 'https://developers.googleblog.com/en/introducing-gemma3/', 'title': 'Introducing Gemma 3: The Developer Guide', 'content': 'Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025', 'score': 0.15816164, 'raw_content': None}, {'url': 'https://www.youtube.com/watch?v=rMSSuY4ppnY', 'title': 'Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube', 'content': \"Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\", 'score': 0.13856693, 'raw_content': None}], 'research_loop_count': 2, 'running_summary': 'Gemma 3 is Google\\'s new open model based on Gemini 2.0, designed to make useful AI technology accessible. It introduces multimodality, supporting vision-language input and text outputs, and handles context windows up to 128k tokens. The model is optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm stack. Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, and local environments, giving developers flexibility in choosing the best fit for their application and infrastructure.\\n\\nThe model uses a new tokenizer for better multilingual support, covering over 140 languages, and was trained on large datasets using the JAX Framework. Gemma 3 is considered the most powerful AI model that can run on one GPU, and its popularity indicates interest in AI technology with lower hardware requirements. However, the definition of an \"open\" or \"open source\" AI model remains a topic of debate, with Google\\'s license restricting usage.\\n\\nGemma 3 provides various tools and integrations, including support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, and Gemma.cpp, allowing developers to choose their preferred tools. The model is also compatible with Google AI Edge, enabling deployment on mobile and web platforms. Additionally, Gemma 3 has been compared to other models, such as QwQ and Deepseek R1 671b, with some considering it the best open-source vision model. \\n\\nFurthermore, Gemma 3 was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework, demonstrating its extensive training dataset. The model\\'s performance and capabilities have been discussed in various online forums and tutorials, including a developer guide and YouTube videos, which provide insights into its potential applications and limitations. Overall, Gemma 3 aims to accelerate AI development across multiple hardware platforms, making it a significant release in the field of artificial intelligence. \\n\\nThere is no information available on a Gemma 3 satellite mission, suggesting that the term \"Gemma 3\" is primarily associated with Google\\'s AI model. The search results do not provide any evidence of a satellite mission with this name, and the focus remains on the AI model\\'s features, capabilities, and potential applications.', 'tweets': [], 'linkedin_posts': []}\n",
      "\u001b[94mRunning function: finalize_summary\u001b[0m\n",
      "\u001b[94mRunning function: finalize_summary\u001b[0m\n",
      "{'research_topic': 'Gemma 3', 'search_query': 'Gemma 3 tokenizer architecture and performance comparison with other multilingual tokenizers like BERT and XLNet', 'web_research_results': [\"Query: Gemma 3 satellite mission\\nSearch Results:\\n\\n1. Gemma 3: Google's new open model based on Gemini 2.0\\n   URL: https://blog.google/technology/developers/gemma-3/\\n   Relevance Score: 0.25014767\\n\\n   Content: Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.\\n\\n2. Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\\n   URL: https://simonw.substack.com/p/notes-on-googles-gemma-3\\n   Relevance Score: 0.21688144\\n\\n   Content: Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands\\n\\n3. Google calls Gemma 3 the most powerful AI model you can run on ...\\n   URL: https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model\\n   Relevance Score: 0.16514862\\n\\n   Content: Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.\\n\\n4. Introducing Gemma 3: The Developer Guide\\n   URL: https://developers.googleblog.com/en/introducing-gemma3/\\n   Relevance Score: 0.15816164\\n\\n   Content: Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025\\n\\n5. Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube\\n   URL: https://www.youtube.com/watch?v=rMSSuY4ppnY\\n   Relevance Score: 0.13856693\\n\\n   Content: Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\\n\", \"Query: Gemma 3 satellite mission\\nSearch Results:\\n\\n1. Gemma 3: Google's new open model based on Gemini 2.0\\n   URL: https://blog.google/technology/developers/gemma-3/\\n   Relevance Score: 0.25014767\\n\\n   Content: Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.\\n\\n2. Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\\n   URL: https://simonw.substack.com/p/notes-on-googles-gemma-3\\n   Relevance Score: 0.21688144\\n\\n   Content: Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands\\n\\n3. Google calls Gemma 3 the most powerful AI model you can run on ...\\n   URL: https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model\\n   Relevance Score: 0.16514862\\n\\n   Content: Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.\\n\\n4. Introducing Gemma 3: The Developer Guide\\n   URL: https://developers.googleblog.com/en/introducing-gemma3/\\n   Relevance Score: 0.15816164\\n\\n   Content: Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025\\n\\n5. Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube\\n   URL: https://www.youtube.com/watch?v=rMSSuY4ppnY\\n   Relevance Score: 0.13856693\\n\\n   Content: Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\\n\"], 'sources_gathered': [{'url': 'https://blog.google/technology/developers/gemma-3/', 'title': \"Gemma 3: Google's new open model based on Gemini 2.0\", 'content': 'Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.', 'score': 0.25014767, 'raw_content': None}, {'url': 'https://simonw.substack.com/p/notes-on-googles-gemma-3', 'title': \"Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\", 'content': 'Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands', 'score': 0.21688144, 'raw_content': None}, {'url': 'https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model', 'title': 'Google calls Gemma 3 the most powerful AI model you can run on ...', 'content': 'Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.', 'score': 0.16514862, 'raw_content': None}, {'url': 'https://developers.googleblog.com/en/introducing-gemma3/', 'title': 'Introducing Gemma 3: The Developer Guide', 'content': 'Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025', 'score': 0.15816164, 'raw_content': None}, {'url': 'https://www.youtube.com/watch?v=rMSSuY4ppnY', 'title': 'Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube', 'content': \"Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\", 'score': 0.13856693, 'raw_content': None}, {'url': 'https://blog.google/technology/developers/gemma-3/', 'title': \"Gemma 3: Google's new open model based on Gemini 2.0\", 'content': 'Gemma 3: Google’s new open model based on Gemini 2.0 The Gemma family of open models is foundational to our commitment to making useful AI technology accessible. Develop with your favorite tools: With support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, Google AI Edge, UnSloth, vLLM and Gemma.cpp, you have the flexibility to choose the best tools for your project. Deploy your way: Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, Iocal environments and other platforms, giving you the flexibility to choose the best fit for your application and infrastructure. Accelerate your AI development across many hardware platforms: Gemma 3 is also optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm™ stack.', 'score': 0.25014767, 'raw_content': None}, {'url': 'https://simonw.substack.com/p/notes-on-googles-gemma-3', 'title': \"Notes on Google's Gemma 3 - Simon Willison's Newsletter - Substack\", 'content': 'Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands', 'score': 0.21688144, 'raw_content': None}, {'url': 'https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model', 'title': 'Google calls Gemma 3 the most powerful AI model you can run on ...', 'content': 'Google calls Gemma 3 the most powerful AI model you can run on one GPU | The Verge Google calls Gemma 3 the most powerful AI model you can run on one GPU Google calls Gemma 3 the most powerful AI model you can run on one GPU Last year it was unclear how much interest there would be in a model like Gemma, however, the popularity of DeepSeek and others shows there is interest in AI tech with lower hardware requirements. What exactly constitutes an “open” or “open source” AI model remains a topic of debate, and with Google’s Gemma, that has focused on the company’s license that restricts what people are allowed to use it for, which has not changed with this new release.', 'score': 0.16514862, 'raw_content': None}, {'url': 'https://developers.googleblog.com/en/introducing-gemma3/', 'title': 'Introducing Gemma 3: The Developer Guide', 'content': 'Introducing Gemma 3: The Developer Guide - Google Developers Blog Gemma 3 uses a new tokenizer for better multilingual support for over 140+ languages and was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework. Gemma<end_of_turn> Gemma who?<end_of_turn> Deploy your way: Gemma 3 offers multiple deployment options, including Google GenAI API, Vertex AI, Cloud Run, Cloud TPU, and Cloud GPU and integrations across platforms, giving you the flexibility to choose the best fit for your use case. Gemma AI Edge Mobile Web How-To Guides Gemma 3 on mobile and web with Google AI Edge March 12, 2025 Gemini AI Announcements State-of-the-art text embedding via the Gemini API March 7, 2025 Gemma AI Announcements Best Practices Safer and Multimodal: Responsible AI with Gemma March 12, 2025', 'score': 0.15816164, 'raw_content': None}, {'url': 'https://www.youtube.com/watch?v=rMSSuY4ppnY', 'title': 'Gemma 3 Google AI Best Local Vision LLM Ever?! - YouTube', 'content': \"Gemma 3 is possibly the best Open Source Vision model but how is it's Chat stacking up against QwQ and Deepseek R1 671b? I was shocked!\", 'score': 0.13856693, 'raw_content': None}], 'research_loop_count': 2, 'running_summary': '## Summary\\n\\nGemma 3 is Google\\'s new open model based on Gemini 2.0, designed to make useful AI technology accessible. It introduces multimodality, supporting vision-language input and text outputs, and handles context windows up to 128k tokens. The model is optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm stack. Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, and local environments, giving developers flexibility in choosing the best fit for their application and infrastructure.\\n\\nThe model uses a new tokenizer for better multilingual support, covering over 140 languages, and was trained on large datasets using the JAX Framework. Gemma 3 is considered the most powerful AI model that can run on one GPU, and its popularity indicates interest in AI technology with lower hardware requirements. However, the definition of an \"open\" or \"open source\" AI model remains a topic of debate, with Google\\'s license restricting usage.\\n\\nGemma 3 provides various tools and integrations, including support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, and Gemma.cpp, allowing developers to choose their preferred tools. The model is also compatible with Google AI Edge, enabling deployment on mobile and web platforms. Additionally, Gemma 3 has been compared to other models, such as QwQ and Deepseek R1 671b, with some considering it the best open-source vision model. \\n\\nFurthermore, Gemma 3 was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework, demonstrating its extensive training dataset. The model\\'s performance and capabilities have been discussed in various online forums and tutorials, including a developer guide and YouTube videos, which provide insights into its potential applications and limitations. Overall, Gemma 3 aims to accelerate AI development across multiple hardware platforms, making it a significant release in the field of artificial intelligence. \\n\\nThere is no information available on a Gemma 3 satellite mission, suggesting that the term \"Gemma 3\" is primarily associated with Google\\'s AI model. The search results do not provide any evidence of a satellite mission with this name, and the focus remains on the AI model\\'s features, capabilities, and potential applications.\\n\\n ### Sources:\\nhttps://blog.google/technology/developers/gemma-3/\\nhttps://simonw.substack.com/p/notes-on-googles-gemma-3\\nhttps://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model\\nhttps://developers.googleblog.com/en/introducing-gemma3/\\nhttps://www.youtube.com/watch?v=rMSSuY4ppnY\\nhttps://blog.google/technology/developers/gemma-3/\\nhttps://simonw.substack.com/p/notes-on-googles-gemma-3\\nhttps://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model\\nhttps://developers.googleblog.com/en/introducing-gemma3/\\nhttps://www.youtube.com/watch?v=rMSSuY4ppnY', 'tweets': [], 'linkedin_posts': []}\n"
     ]
    }
   ],
   "source": [
    "final_tweets = []\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "for event in graph.stream(summary_state, config,stream_mode=\"values\"):\n",
    "    print(event)\n",
    "\n",
    "    final_tweets = event['tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Summary\n",
      "\n",
      "Gemma 3 is Google's new open model based on Gemini 2.0, designed to make useful AI technology accessible. It introduces multimodality, supporting vision-language input and text outputs, and handles context windows up to 128k tokens. The model is optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm stack. Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, the Google GenAI API, and local environments, giving developers flexibility in choosing the best fit for their application and infrastructure.\n",
      "\n",
      "The model uses a new tokenizer for better multilingual support, covering over 140 languages, and was trained on large datasets using the JAX Framework. Gemma 3 is considered the most powerful AI model that can run on one GPU, and its popularity indicates interest in AI technology with lower hardware requirements. However, the definition of an \"open\" or \"open source\" AI model remains a topic of debate, with Google's license restricting usage.\n",
      "\n",
      "Gemma 3 provides various tools and integrations, including support for Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, and Gemma.cpp, allowing developers to choose their preferred tools. The model is also compatible with Google AI Edge, enabling deployment on mobile and web platforms. Additionally, Gemma 3 has been compared to other models, such as QwQ and Deepseek R1 671b, with some considering it the best open-source vision model. \n",
      "\n",
      "Furthermore, Gemma 3 was trained on 2T tokens for 1B, 4T for 4B, 12T for 12B, and 14T tokens for 27B, on Google TPUs using the JAX Framework, demonstrating its extensive training dataset. The model's performance and capabilities have been discussed in various online forums and tutorials, including a developer guide and YouTube videos, which provide insights into its potential applications and limitations. Overall, Gemma 3 aims to accelerate AI development across multiple hardware platforms, making it a significant release in the field of artificial intelligence. \n",
      "\n",
      "There is no information available on a Gemma 3 satellite mission, suggesting that the term \"Gemma 3\" is primarily associated with Google's AI model. The search results do not provide any evidence of a satellite mission with this name, and the focus remains on the AI model's features, capabilities, and potential applications.\n",
      "\n",
      " ### Sources:\n",
      "https://blog.google/technology/developers/gemma-3/\n",
      "https://simonw.substack.com/p/notes-on-googles-gemma-3\n",
      "https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model\n",
      "https://developers.googleblog.com/en/introducing-gemma3/\n",
      "https://www.youtube.com/watch?v=rMSSuY4ppnY\n",
      "https://blog.google/technology/developers/gemma-3/\n",
      "https://simonw.substack.com/p/notes-on-googles-gemma-3\n",
      "https://www.theverge.com/ai-artificial-intelligence/627968/google-gemma-3-open-ai-model\n",
      "https://developers.googleblog.com/en/introducing-gemma3/\n",
      "https://www.youtube.com/watch?v=rMSSuY4ppnY\n"
     ]
    }
   ],
   "source": [
    "print(event['running_summary'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'human_approval': None}\n",
      "{'linkedin_x_agent': {'tweets': [{'content': \"Meet Gemma 3, Google's new open AI model! 🚀 With multimodality, 128k token context windows, and support for 140+ languages, it's revolutionizing AI accessibility. What will you build with it? 🤔 #Gemma3 #AI\", 'virality_score': 9, 'justification': 'Introduces a new technology, sparks curiosity, and encourages engagement.'}, {'content': \"Did you know Gemma 3 is the most powerful AI model that can run on one GPU? 💻 It's a game-changer for developers and AI enthusiasts! What are your thoughts on this breakthrough? Share with us! #Gemma3 #AIModel\", 'virality_score': 8, 'justification': 'Surprising statistic, encourages discussion and sharing.'}, {'content': 'Gemma 3 is not just powerful, but also flexible! 🌈 With deployment options like Vertex AI, Cloud Run, and local environments, developers have the freedom to choose. How will you deploy Gemma 3? #Gemma3 #AIDeployment', 'virality_score': 7, 'justification': 'Highlights a key feature, asks a question to spark discussion.'}, {'content': \"What does 'open' mean in AI? 🤔 Google's Gemma 3 raises important questions about AI model licensing and usage. Join the conversation and share your thoughts! #Gemma3 #OpenAI\", 'virality_score': 8, 'justification': 'Taps into a current debate, encourages discussion and sharing.'}, {'content': 'Get ready to unleash your creativity with Gemma 3! 🎨 With support for vision-language input and text outputs, the possibilities are endless. What will you create? #Gemma3 #AIArt', 'virality_score': 9, 'justification': 'Inspires creativity, encourages users to share their work.'}, {'content': \"Gemma 3 is trained on massive datasets and can handle up to 128k tokens! 🤯 What does this mean for the future of AI? Share your thoughts and let's discuss! #Gemma3 #AIModel\", 'virality_score': 8, 'justification': 'Highlights a key feature, sparks discussion and curiosity.'}, {'content': \"Developers, rejoice! 🎉 Gemma 3 supports a range of tools and integrations, including Hugging Face Transformers and PyTorch. What's your go-to tool for AI development? #Gemma3 #AIDevelopment\", 'virality_score': 7, 'justification': 'Highlights a key feature, asks a question to spark discussion.'}, {'content': \"How will Gemma 3 change the AI landscape? 🌐 With its powerful capabilities and accessibility, it's poised to accelerate AI development across multiple hardware platforms. Share your predictions! #Gemma3 #AI\", 'virality_score': 8, 'justification': 'Encourages discussion, sparks curiosity and speculation.'}, {'content': 'New to Gemma 3? 🤔 Check out the official developer guide and YouTube tutorials to get started! 📚 What resources do you use to learn about AI? Share with us! #Gemma3 #AIGuide', 'virality_score': 6, 'justification': 'Provides useful resources, asks a question to spark discussion.'}, {'content': \"Gemma 3 vs other AI models: how does it stack up? 🤔 With its impressive capabilities and accessibility, it's a strong contender. What's your take on the AI model landscape? #Gemma3 #AIModel\", 'virality_score': 8, 'justification': 'Encourages comparison and discussion, sparks curiosity and debate.'}], 'linkedin_posts': [{'headline': 'Revolutionizing AI Accessibility: Unpacking Gemma 3', 'content': \"The recent introduction of Gemma 3, Google's new open model based on Gemini 2.0, marks a significant milestone in making useful AI technology accessible to a broader audience. By supporting vision-language input and text outputs, and handling context windows up to 128k tokens, Gemma 3 is poised to accelerate AI development across multiple hardware platforms.\\n\\nOne of the standout features of Gemma 3 is its multimodality, allowing for more flexible and interactive AI applications. Additionally, the model's compatibility with various tools and integrations, including Hugging Face Transformers and Google AI Edge, enables developers to choose their preferred tools and deploy on mobile and web platforms.\\n\\nHowever, the definition of an 'open' or 'open source' AI model remains a topic of debate, with Google's license restricting usage. As we move forward, it's essential to consider the implications of these restrictions on the development and adoption of AI technology.\\n\\nWhat are your thoughts on the potential impact of Gemma 3 on the AI landscape? How do you envision this technology being used in your industry?\\n\\nTakeaway: Gemma 3 has the potential to democratize access to AI technology, but it's crucial to address the ongoing debate surrounding open-source AI models and their usage restrictions.\", 'hashtags': ['AIAccessibility', 'Gemma3', 'OpenSourceAI', 'ArtificialIntelligence'], 'effectiveness_score': 9, 'strategic_value': 'Positions the author as a knowledgeable expert in AI technology, highlighting the potential benefits and challenges of Gemma 3.'}, {'headline': 'Gemma 3: Unlocking the Power of Multimodal AI', 'content': \"Gemma 3, Google's latest open model, is designed to support vision-language input and text outputs, making it an exciting development in the field of multimodal AI. By handling context windows up to 128k tokens, Gemma 3 enables more complex and nuanced AI applications, from image recognition to natural language processing.\\n\\nThe model's multimodality is a significant advantage, allowing developers to create more interactive and engaging AI experiences. For instance, Gemma 3 can be used to build AI-powered chatbots that can understand and respond to visual inputs, such as images or videos.\\n\\nTo get the most out of Gemma 3, it's essential to understand its capabilities and limitations. The model is optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm stack, providing flexibility in deployment options.\\n\\nWhat are some potential use cases for Gemma 3 in your industry? How can you leverage its multimodal capabilities to drive innovation and growth?\\n\\nTakeaway: Gemma 3's multimodality and support for vision-language input and text outputs make it an attractive option for developers looking to build more sophisticated AI applications.\", 'hashtags': ['MultimodalAI', 'Gemma3', 'AIInnovation', 'ArtificialIntelligence'], 'effectiveness_score': 8.5, 'strategic_value': \"Highlights the potential benefits of Gemma 3's multimodality, positioning the author as a thought leader in AI innovation.\"}, {'headline': 'The Future of AI: Gemma 3 and the Rise of Open-Source Models', 'content': \"The introduction of Gemma 3, Google's new open model, marks a significant shift in the AI landscape. As the most powerful AI model that can run on one GPU, Gemma 3 is poised to accelerate AI development across multiple hardware platforms, making it more accessible to a broader audience.\\n\\nHowever, the definition of an 'open' or 'open source' AI model remains a topic of debate, with Google's license restricting usage. As we move forward, it's essential to consider the implications of these restrictions on the development and adoption of AI technology.\\n\\nGemma 3's popularity indicates a growing interest in AI technology with lower hardware requirements. As the demand for more accessible and affordable AI solutions continues to grow, it's likely that we'll see more open-source models emerge.\\n\\nWhat are your thoughts on the future of AI and the role of open-source models? How can we balance the need for accessibility with the need for responsible AI development?\\n\\nTakeaway: Gemma 3 represents a significant step towards making AI more accessible, but it's crucial to address the ongoing debate surrounding open-source AI models and their usage restrictions.\", 'hashtags': ['AIFuture', 'Gemma3', 'OpenSourceAI', 'ArtificialIntelligence'], 'effectiveness_score': 9, 'strategic_value': 'Positions the author as a thought leader in AI, highlighting the potential benefits and challenges of open-source models.'}, {'headline': \"Getting Started with Gemma 3: A Developer's Guide\", 'content': \"Gemma 3, Google's new open model, offers a range of tools and integrations to help developers get started with building AI applications. From Hugging Face Transformers to Google AI Edge, the model provides flexibility in deployment options, allowing developers to choose their preferred tools and platforms.\\n\\nTo get the most out of Gemma 3, it's essential to understand its capabilities and limitations. The model is optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm stack, providing a range of deployment options.\\n\\nHere are some key takeaways for developers looking to get started with Gemma 3:\\n\\n*   Familiarize yourself with the model's capabilities and limitations\\n*   Choose your preferred tools and integrations\\n*   Experiment with different deployment options\\n*   Join online communities and forums to stay up-to-date with the latest developments\\n\\nWhat are some potential challenges or obstacles that developers may face when working with Gemma 3? How can we address these challenges and ensure successful adoption?\\n\\nTakeaway: Gemma 3 provides a range of tools and integrations to help developers get started with building AI applications, but it's essential to understand its capabilities and limitations.\", 'hashtags': ['Gemma3', 'AIDevelopment', 'DeveloperGuide', 'ArtificialIntelligence'], 'effectiveness_score': 8, 'strategic_value': 'Provides a practical guide for developers looking to get started with Gemma 3, positioning the author as a knowledgeable expert in AI development.'}, {'headline': 'Gemma 3: A Game-Changer for AI-Powered Applications', 'content': \"Gemma 3, Google's new open model, is poised to revolutionize the development of AI-powered applications. With its support for vision-language input and text outputs, and handling context windows up to 128k tokens, Gemma 3 enables more complex and nuanced AI experiences.\\n\\nThe model's multimodality is a significant advantage, allowing developers to create more interactive and engaging AI applications. For instance, Gemma 3 can be used to build AI-powered chatbots that can understand and respond to visual inputs, such as images or videos.\\n\\nGemma 3's popularity indicates a growing interest in AI technology with lower hardware requirements. As the demand for more accessible and affordable AI solutions continues to grow, it's likely that we'll see more open-source models emerge.\\n\\nWhat are some potential use cases for Gemma 3 in your industry? How can you leverage its multimodal capabilities to drive innovation and growth?\\n\\nTakeaway: Gemma 3 has the potential to drive significant innovation in AI-powered applications, but it's essential to consider the implications of its usage restrictions and the ongoing debate surrounding open-source AI models.\", 'hashtags': ['Gemma3', 'AIApplications', 'ArtificialIntelligence', 'Innovation'], 'effectiveness_score': 8.5, 'strategic_value': 'Highlights the potential benefits of Gemma 3, positioning the author as a thought leader in AI innovation.'}, {'headline': 'The Impact of Gemma 3 on the AI Landscape', 'content': \"The introduction of Gemma 3, Google's new open model, marks a significant shift in the AI landscape. As the most powerful AI model that can run on one GPU, Gemma 3 is poised to accelerate AI development across multiple hardware platforms, making it more accessible to a broader audience.\\n\\nGemma 3's popularity indicates a growing interest in AI technology with lower hardware requirements. As the demand for more accessible and affordable AI solutions continues to grow, it's likely that we'll see more open-source models emerge.\\n\\nThe model's multimodality is a significant advantage, allowing developers to create more interactive and engaging AI applications. For instance, Gemma 3 can be used to build AI-powered chatbots that can understand and respond to visual inputs, such as images or videos.\\n\\nWhat are your thoughts on the potential impact of Gemma 3 on the AI landscape? How can we balance the need for accessibility with the need for responsible AI development?\\n\\nTakeaway: Gemma 3 represents a significant step towards making AI more accessible, but it's crucial to address the ongoing debate surrounding open-source AI models and their usage restrictions.\", 'hashtags': ['AIImpact', 'Gemma3', 'OpenSourceAI', 'ArtificialIntelligence'], 'effectiveness_score': 9, 'strategic_value': 'Positions the author as a thought leader in AI, highlighting the potential benefits and challenges of Gemma 3.'}]}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for chunk in graph.stream(Command(resume=\"both\"), config):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'headline': 'Revolutionizing AI Accessibility: Unpacking Gemma 3',\n",
       "  'content': \"The recent introduction of Gemma 3, Google's new open model based on Gemini 2.0, marks a significant milestone in making useful AI technology accessible to a broader audience. By supporting vision-language input and text outputs, and handling context windows up to 128k tokens, Gemma 3 is poised to accelerate AI development across multiple hardware platforms.\\n\\nOne of the standout features of Gemma 3 is its multimodality, allowing for more flexible and interactive AI applications. Additionally, the model's compatibility with various tools and integrations, including Hugging Face Transformers and Google AI Edge, enables developers to choose their preferred tools and deploy on mobile and web platforms.\\n\\nHowever, the definition of an 'open' or 'open source' AI model remains a topic of debate, with Google's license restricting usage. As we move forward, it's essential to consider the implications of these restrictions on the development and adoption of AI technology.\\n\\nWhat are your thoughts on the potential impact of Gemma 3 on the AI landscape? How do you envision this technology being used in your industry?\\n\\nTakeaway: Gemma 3 has the potential to democratize access to AI technology, but it's crucial to address the ongoing debate surrounding open-source AI models and their usage restrictions.\",\n",
       "  'hashtags': ['AIAccessibility',\n",
       "   'Gemma3',\n",
       "   'OpenSourceAI',\n",
       "   'ArtificialIntelligence'],\n",
       "  'effectiveness_score': 9,\n",
       "  'strategic_value': 'Positions the author as a knowledgeable expert in AI technology, highlighting the potential benefits and challenges of Gemma 3.'},\n",
       " {'headline': 'Gemma 3: Unlocking the Power of Multimodal AI',\n",
       "  'content': \"Gemma 3, Google's latest open model, is designed to support vision-language input and text outputs, making it an exciting development in the field of multimodal AI. By handling context windows up to 128k tokens, Gemma 3 enables more complex and nuanced AI applications, from image recognition to natural language processing.\\n\\nThe model's multimodality is a significant advantage, allowing developers to create more interactive and engaging AI experiences. For instance, Gemma 3 can be used to build AI-powered chatbots that can understand and respond to visual inputs, such as images or videos.\\n\\nTo get the most out of Gemma 3, it's essential to understand its capabilities and limitations. The model is optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm stack, providing flexibility in deployment options.\\n\\nWhat are some potential use cases for Gemma 3 in your industry? How can you leverage its multimodal capabilities to drive innovation and growth?\\n\\nTakeaway: Gemma 3's multimodality and support for vision-language input and text outputs make it an attractive option for developers looking to build more sophisticated AI applications.\",\n",
       "  'hashtags': ['MultimodalAI',\n",
       "   'Gemma3',\n",
       "   'AIInnovation',\n",
       "   'ArtificialIntelligence'],\n",
       "  'effectiveness_score': 8.5,\n",
       "  'strategic_value': \"Highlights the potential benefits of Gemma 3's multimodality, positioning the author as a thought leader in AI innovation.\"},\n",
       " {'headline': 'The Future of AI: Gemma 3 and the Rise of Open-Source Models',\n",
       "  'content': \"The introduction of Gemma 3, Google's new open model, marks a significant shift in the AI landscape. As the most powerful AI model that can run on one GPU, Gemma 3 is poised to accelerate AI development across multiple hardware platforms, making it more accessible to a broader audience.\\n\\nHowever, the definition of an 'open' or 'open source' AI model remains a topic of debate, with Google's license restricting usage. As we move forward, it's essential to consider the implications of these restrictions on the development and adoption of AI technology.\\n\\nGemma 3's popularity indicates a growing interest in AI technology with lower hardware requirements. As the demand for more accessible and affordable AI solutions continues to grow, it's likely that we'll see more open-source models emerge.\\n\\nWhat are your thoughts on the future of AI and the role of open-source models? How can we balance the need for accessibility with the need for responsible AI development?\\n\\nTakeaway: Gemma 3 represents a significant step towards making AI more accessible, but it's crucial to address the ongoing debate surrounding open-source AI models and their usage restrictions.\",\n",
       "  'hashtags': ['AIFuture', 'Gemma3', 'OpenSourceAI', 'ArtificialIntelligence'],\n",
       "  'effectiveness_score': 9,\n",
       "  'strategic_value': 'Positions the author as a thought leader in AI, highlighting the potential benefits and challenges of open-source models.'},\n",
       " {'headline': \"Getting Started with Gemma 3: A Developer's Guide\",\n",
       "  'content': \"Gemma 3, Google's new open model, offers a range of tools and integrations to help developers get started with building AI applications. From Hugging Face Transformers to Google AI Edge, the model provides flexibility in deployment options, allowing developers to choose their preferred tools and platforms.\\n\\nTo get the most out of Gemma 3, it's essential to understand its capabilities and limitations. The model is optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm stack, providing a range of deployment options.\\n\\nHere are some key takeaways for developers looking to get started with Gemma 3:\\n\\n*   Familiarize yourself with the model's capabilities and limitations\\n*   Choose your preferred tools and integrations\\n*   Experiment with different deployment options\\n*   Join online communities and forums to stay up-to-date with the latest developments\\n\\nWhat are some potential challenges or obstacles that developers may face when working with Gemma 3? How can we address these challenges and ensure successful adoption?\\n\\nTakeaway: Gemma 3 provides a range of tools and integrations to help developers get started with building AI applications, but it's essential to understand its capabilities and limitations.\",\n",
       "  'hashtags': ['Gemma3',\n",
       "   'AIDevelopment',\n",
       "   'DeveloperGuide',\n",
       "   'ArtificialIntelligence'],\n",
       "  'effectiveness_score': 8,\n",
       "  'strategic_value': 'Provides a practical guide for developers looking to get started with Gemma 3, positioning the author as a knowledgeable expert in AI development.'},\n",
       " {'headline': 'Gemma 3: A Game-Changer for AI-Powered Applications',\n",
       "  'content': \"Gemma 3, Google's new open model, is poised to revolutionize the development of AI-powered applications. With its support for vision-language input and text outputs, and handling context windows up to 128k tokens, Gemma 3 enables more complex and nuanced AI experiences.\\n\\nThe model's multimodality is a significant advantage, allowing developers to create more interactive and engaging AI applications. For instance, Gemma 3 can be used to build AI-powered chatbots that can understand and respond to visual inputs, such as images or videos.\\n\\nGemma 3's popularity indicates a growing interest in AI technology with lower hardware requirements. As the demand for more accessible and affordable AI solutions continues to grow, it's likely that we'll see more open-source models emerge.\\n\\nWhat are some potential use cases for Gemma 3 in your industry? How can you leverage its multimodal capabilities to drive innovation and growth?\\n\\nTakeaway: Gemma 3 has the potential to drive significant innovation in AI-powered applications, but it's essential to consider the implications of its usage restrictions and the ongoing debate surrounding open-source AI models.\",\n",
       "  'hashtags': ['Gemma3',\n",
       "   'AIApplications',\n",
       "   'ArtificialIntelligence',\n",
       "   'Innovation'],\n",
       "  'effectiveness_score': 8.5,\n",
       "  'strategic_value': 'Highlights the potential benefits of Gemma 3, positioning the author as a thought leader in AI innovation.'},\n",
       " {'headline': 'The Impact of Gemma 3 on the AI Landscape',\n",
       "  'content': \"The introduction of Gemma 3, Google's new open model, marks a significant shift in the AI landscape. As the most powerful AI model that can run on one GPU, Gemma 3 is poised to accelerate AI development across multiple hardware platforms, making it more accessible to a broader audience.\\n\\nGemma 3's popularity indicates a growing interest in AI technology with lower hardware requirements. As the demand for more accessible and affordable AI solutions continues to grow, it's likely that we'll see more open-source models emerge.\\n\\nThe model's multimodality is a significant advantage, allowing developers to create more interactive and engaging AI applications. For instance, Gemma 3 can be used to build AI-powered chatbots that can understand and respond to visual inputs, such as images or videos.\\n\\nWhat are your thoughts on the potential impact of Gemma 3 on the AI landscape? How can we balance the need for accessibility with the need for responsible AI development?\\n\\nTakeaway: Gemma 3 represents a significant step towards making AI more accessible, but it's crucial to address the ongoing debate surrounding open-source AI models and their usage restrictions.\",\n",
       "  'hashtags': ['AIImpact', 'Gemma3', 'OpenSourceAI', 'ArtificialIntelligence'],\n",
       "  'effectiveness_score': 9,\n",
       "  'strategic_value': 'Positions the author as a thought leader in AI, highlighting the potential benefits and challenges of Gemma 3.'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk['linkedin_x_agent']['linkedin_posts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': \"Meet Gemma 3, Google's new open AI model! 🚀 With multimodality, 128k token context windows, and support for 140+ languages, it's revolutionizing AI accessibility. What will you build with it? 🤔 #Gemma3 #AI\",\n",
       "  'virality_score': 9,\n",
       "  'justification': 'Introduces a new technology, sparks curiosity, and encourages engagement.'},\n",
       " {'content': \"Did you know Gemma 3 is the most powerful AI model that can run on one GPU? 💻 It's a game-changer for developers and AI enthusiasts! What are your thoughts on this breakthrough? Share with us! #Gemma3 #AIModel\",\n",
       "  'virality_score': 8,\n",
       "  'justification': 'Surprising statistic, encourages discussion and sharing.'},\n",
       " {'content': 'Gemma 3 is not just powerful, but also flexible! 🌈 With deployment options like Vertex AI, Cloud Run, and local environments, developers have the freedom to choose. How will you deploy Gemma 3? #Gemma3 #AIDeployment',\n",
       "  'virality_score': 7,\n",
       "  'justification': 'Highlights a key feature, asks a question to spark discussion.'},\n",
       " {'content': \"What does 'open' mean in AI? 🤔 Google's Gemma 3 raises important questions about AI model licensing and usage. Join the conversation and share your thoughts! #Gemma3 #OpenAI\",\n",
       "  'virality_score': 8,\n",
       "  'justification': 'Taps into a current debate, encourages discussion and sharing.'},\n",
       " {'content': 'Get ready to unleash your creativity with Gemma 3! 🎨 With support for vision-language input and text outputs, the possibilities are endless. What will you create? #Gemma3 #AIArt',\n",
       "  'virality_score': 9,\n",
       "  'justification': 'Inspires creativity, encourages users to share their work.'},\n",
       " {'content': \"Gemma 3 is trained on massive datasets and can handle up to 128k tokens! 🤯 What does this mean for the future of AI? Share your thoughts and let's discuss! #Gemma3 #AIModel\",\n",
       "  'virality_score': 8,\n",
       "  'justification': 'Highlights a key feature, sparks discussion and curiosity.'},\n",
       " {'content': \"Developers, rejoice! 🎉 Gemma 3 supports a range of tools and integrations, including Hugging Face Transformers and PyTorch. What's your go-to tool for AI development? #Gemma3 #AIDevelopment\",\n",
       "  'virality_score': 7,\n",
       "  'justification': 'Highlights a key feature, asks a question to spark discussion.'},\n",
       " {'content': \"How will Gemma 3 change the AI landscape? 🌐 With its powerful capabilities and accessibility, it's poised to accelerate AI development across multiple hardware platforms. Share your predictions! #Gemma3 #AI\",\n",
       "  'virality_score': 8,\n",
       "  'justification': 'Encourages discussion, sparks curiosity and speculation.'},\n",
       " {'content': 'New to Gemma 3? 🤔 Check out the official developer guide and YouTube tutorials to get started! 📚 What resources do you use to learn about AI? Share with us! #Gemma3 #AIGuide',\n",
       "  'virality_score': 6,\n",
       "  'justification': 'Provides useful resources, asks a question to spark discussion.'},\n",
       " {'content': \"Gemma 3 vs other AI models: how does it stack up? 🤔 With its impressive capabilities and accessibility, it's a strong contender. What's your take on the AI model landscape? #Gemma3 #AIModel\",\n",
       "  'virality_score': 8,\n",
       "  'justification': 'Encourages comparison and discussion, sparks curiosity and debate.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk['linkedin_x_agent']['tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Gemma 3\"\n",
    "summary_state = SummaryState(\n",
    "    research_topic=topic,\n",
    "    search_query='',\n",
    "    web_research_results=[],\n",
    "    sources_gathered=[],\n",
    "    research_loop_count=0,\n",
    "    running_summary=None,\n",
    "    tweets=[]\n",
    ")\n",
    "\n",
    "summary_state.running_summary = event['running_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.assistant.graph import linkedin_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = linkedin_agent(summary_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlocking AI Potential: Exploring Google's Gemma 3\n",
      "Google has recently unveiled Gemma 3, an open model based on Gemini 2.0, designed to make AI technology more accessible. This powerful model introduces multimodality, supporting vision-language input and text outputs, and can handle context windows of up to 128k tokens. \n",
      "\n",
      "With its ability to run on a single GPU and support for over 140 languages, Gemma 3 is poised to revolutionize AI development across various hardware platforms. But what does this mean for developers and the future of AI? \n",
      "\n",
      "Let's dive into the key features and implications of Gemma 3, including its deployment options, tokenizer, and potential applications. \n",
      "\n",
      "Key Takeaways: \n",
      "* Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, and local environments \n",
      "* The model uses a new tokenizer for better multilingual support, covering over 140 languages \n",
      "* Gemma 3 is considered one of the most powerful AI models that can run on a single GPU \n",
      "\n",
      "What are your thoughts on Gemma 3 and its potential impact on the AI landscape? Share your insights and let's discuss!\n",
      "['AI', 'Gemma3', 'Google', 'MachineLearning']\n",
      "Demystifying Gemma 3: Separating Fact from Fiction\n",
      "As Google's Gemma 3 continues to make waves in the AI community, there's been a lot of discussion about what it means for the future of AI development. But with all the hype, it's easy to get lost in the noise. \n",
      "\n",
      "Let's take a step back and separate fact from fiction. What are the real capabilities and limitations of Gemma 3? How does it compare to other AI models on the market? \n",
      "\n",
      "In this post, we'll delve into the details of Gemma 3, including its architecture, training data, and potential applications. We'll also explore the debate surrounding its 'open' status and what this means for developers. \n",
      "\n",
      "Key Insights: \n",
      "* Gemma 3 is trained on large datasets using the JAX Framework \n",
      "* The model is optimized for Google Cloud TPUs and integrates with AMD GPUs via the open-source ROCm stack \n",
      "* Gemma 3 has been compared to other AI models, such as QwQ and Deepseek R1 671b \n",
      "\n",
      "What are your thoughts on the potential of Gemma 3? Share your perspectives and let's discuss!\n",
      "['Gemma3', 'AI', 'MachineLearning', 'Google']\n",
      "Getting Started with Gemma 3: A Developer's Guide\n",
      "Are you excited to start working with Google's Gemma 3, but not sure where to begin? Look no further! In this post, we'll provide a step-by-step guide to getting started with Gemma 3, including deployment options, popular tools, and resources. \n",
      "\n",
      "From setting up your environment to deploying your application, we'll cover it all. Whether you're a seasoned developer or just starting out, this guide will help you unlock the full potential of Gemma 3. \n",
      "\n",
      "Key Takeaways: \n",
      "* Gemma 3 offers multiple deployment options, including Vertex AI, Cloud Run, and local environments \n",
      "* Popular tools for working with Gemma 3 include Hugging Face Transformers, Ollama, JAX, Keras, PyTorch, and Gemma.cpp \n",
      "* Google provides guides and resources for developers to work with Gemma 3, including tutorials on deploying the model on mobile and web platforms \n",
      "\n",
      "What are your favorite tools and resources for working with Gemma 3? Share your tips and tricks and let's discuss!\n",
      "['Gemma3', 'AI', 'MachineLearning', 'Google']\n",
      "The Future of AI: What Gemma 3 Means for Your Business\n",
      "As AI technology continues to advance, it's becoming increasingly important for businesses to stay ahead of the curve. Google's Gemma 3 is a significant step forward in AI development, offering unprecedented capabilities and potential applications. \n",
      "\n",
      "But what does this mean for your business? How can you leverage Gemma 3 to drive innovation and growth? \n",
      "\n",
      "In this post, we'll explore the potential implications of Gemma 3 for businesses, including new opportunities for automation, enhanced customer experiences, and improved decision-making. \n",
      "\n",
      "Key Insights: \n",
      "* Gemma 3 has the potential to revolutionize AI development across various hardware platforms \n",
      "* The model's ability to run on a single GPU makes it more accessible to businesses of all sizes \n",
      "* Gemma 3's multilingual support and vision-language capabilities open up new possibilities for global businesses \n",
      "\n",
      "What are your thoughts on the potential of Gemma 3 for your business? Share your perspectives and let's discuss!\n",
      "['AI', 'Gemma3', 'Business', 'Innovation']\n",
      "Responsible AI Development with Gemma 3: Best Practices and Considerations\n",
      "As AI technology becomes more powerful and accessible, it's becoming increasingly important to prioritize responsible AI development. Google's Gemma 3 is a significant step forward in AI development, but it also raises important questions about ethics and accountability. \n",
      "\n",
      "In this post, we'll explore the best practices and considerations for responsible AI development with Gemma 3, including data quality, model transparency, and human oversight. \n",
      "\n",
      "Key Takeaways: \n",
      "* Gemma 3's license restricts certain uses, highlighting the need for careful consideration of AI development \n",
      "* Developers should prioritize data quality and model transparency when working with Gemma 3 \n",
      "* Human oversight and accountability are crucial for ensuring responsible AI development \n",
      "\n",
      "What are your thoughts on responsible AI development with Gemma 3? Share your perspectives and let's discuss!\n",
      "['AI', 'Gemma3', 'ResponsibleAI', 'Ethics']\n",
      "Gemma 3 in Action: Real-World Applications and Success Stories\n",
      "Google's Gemma 3 is more than just a powerful AI model - it's a tool with real-world applications and potential for driving innovation. But what does this look like in practice? \n",
      "\n",
      "In this post, we'll explore real-world applications and success stories of Gemma 3, including use cases in healthcare, finance, and education. \n",
      "\n",
      "From automating tasks to enhancing customer experiences, we'll delve into the ways that Gemma 3 is being used to drive business value and improve lives. \n",
      "\n",
      "Key Insights: \n",
      "* Gemma 3 has been used in healthcare to improve patient outcomes and streamline clinical workflows \n",
      "* In finance, Gemma 3 has been used to enhance customer service and detect fraud \n",
      "* In education, Gemma 3 has been used to personalize learning experiences and improve student outcomes \n",
      "\n",
      "What are your favorite examples of Gemma 3 in action? Share your stories and let's discuss!\n",
      "['Gemma3', 'AI', 'MachineLearning', 'SuccessStories']\n"
     ]
    }
   ],
   "source": [
    "for i in res['linkedin_posts']:\n",
    "    print(i['headline'])\n",
    "    print(i['content'])\n",
    "    print(i['hashtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
